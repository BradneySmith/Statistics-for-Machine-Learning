# Statistics for Machine Learning

## Overview

This repository began as a collection of notebooks covering statistics topics that are useful for understanding machine learning methods. Over time, this has evolved to cover topics from the very fundamentals of statistics, linear algebra and data science, to building many of the most common machine learning models in industry from scratch. The repository is split into chapters, each tackling a specific topic. Each chapter is made up of several notebooks which dive into the theory behind different areas of machine learning. These derive the relevent equations using KaTex and implement the methods programmatically using Python. The end of every notebook contains a Further Reading section which points to useful resources that can be used to explore each topic further.

&nbsp;

## Repository Highlights

| <img width="1106" alt="image" src="https://user-images.githubusercontent.com/39648391/172399826-c8fb6b14-3004-4cff-80cb-4c652508e46c.png"> | <img width="1111" alt="image" src="https://user-images.githubusercontent.com/39648391/172665123-e024ae6c-a5c2-49e5-86a2-e7fcdca40083.png"> |
|:------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------:|
|                    k-Means Clustering algorithm written in Python, implementing k-Means++ intelligent centroid spacing.                    |                  Agglomerative Hierarchical Clustering algorithm written in Python, offering 4 different linkage methods.                  |

&nbsp;

## Chapter 1 - Statistics Fundamentals

1.1 - [Introduction to Statistics](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%201%20-%20Statistics%20Fundamentals/1.1%20-%20Introduction%20to%20Statistics.ipynb)

1.2 - [Basic Data Visualisation](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%201%20-%20Statistics%20Fundamentals/1.2%20-%20Basic%20Data%20Visualisation.ipynb)

1.3 - Probability & Baye's Theorem

1.4 - [Probability Distributions & Expected Values](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%201%20-%20Statistics%20Fundamentals/1.4%20-%20Probability%20Distributions%20%26%20Expected%20Values.ipynb)

1.5 - Distributions in Data (Including Log Normal Distributions)

1.6 - [Sampling Distributions & Estimators](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%201%20-%20Statistics%20Fundamentals/1.6%20-%20Sampling%20Distributions%20%26%20Estimators.ipynb)

1.7 - Confidence Intervals & t-Distributions

1.8 - Hypothesis Testing & p-Values

1.9 - [Covariance and the Covariance Matrix](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%203%20-%20Supervised%20Learning:%20Regression/3.1%20-%20Covariance%20and%20the%20Covariance%20Matrix.ipynb)

1.10 - [Pearson's Correlation Coefficient and R Squared](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%203%20-%20Supervised%20Learning:%20Regression/3.2%20-%20Pearson's%20Correlation%20Coefficient%20and%20R%20Squared.ipynb)

&nbsp;


## Chapter 2 - Machine Learning Fundamentals

2.1 - [Introduction to Machine Learning](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%202%20-%20Machine%20Learning%20Fundamentals/2.1%20-%20Introduction%20to%20Machine%20Learning.ipynb)

2.2 - Model Evaluation Metrics

2.3 - Machine Learning Pipelines

&nbsp;


## Chapter 3 - Supervised Learning: Regression

3.1 - [Simple Linear Regression](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%203%20-%20Supervised%20Learning:%20Regression/3.3%20-%20Least%20Squares%20and%20Simple%20Linear%20Regression.ipynb)

3.2 - Multiple Regression

3.3 - [Regression Trees](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%203%20-%20Supervised%20Learning:%20Regression/3.5%20-%20Regression%20Trees.ipynb)

3.4 - Quantile Regression

&nbsp;


## Chapter 4 - Supervised Learning: Classification

4.1 - Logistic Regression

4.2 - [k-Nearest Neighbors](https://github.com/BradneySmith/k-Nearest-Neighbors/blob/main/Digit%20Recognition.ipynb)

4.3 - Support Vector Machines

4.4 - Classification Trees

4.5 - Random Forests

&nbsp; 


## Chapter 5 - Unsupervised Learning

5.1 - [K-Means Clustering](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%205%20-%20Unsupervised%20Learning/5.1%20-%20k-Means%20Clustering.ipynb)

5.2 - [Hierarchical Agglomerative Clustering](https://github.com/BradneySmith/Statistics-for-Machine-Learning/blob/main/Chapter%205%20-%20Unsupervised%20Learning/5.2%20-%20Hierarchical%20Agglomerative%20Clustering.ipynb)

5.3 - Gaussian Mixture Models

5.4 - DBSCAN Clustering

5.5 - Anomaly Detection

5.6 - Principal Component Analysis

5.7 - Kernel Density Estimation

&nbsp;

## Chapter 6 - Neural Networks and Deep Learning

&nbsp;


## Future Work

### *Introduction to Statistics*
- Update reference to Sampling a Distribution & Bessel's Correction

### *Basic Data Visualisation*
- Add Venn diagrams and time series plots

### *Sampling a Distibution & Bessel's Correction*
- Describe coefficient of variation
- A explanation for how to sample data, and what design decisions to make

&nbsp;
___

## Further Reading

[1] [An Introduction to the Science of Statistics: From Theory to Implementation - Preliminary Edition (Joseph C. Watkins)](https://www.math.arizona.edu/~jwatkins/statbook.pdf)

[2] [Introduction to Statistics and Data Analysis - 3rd Edition (Roxy Peck, Chris Olsen, Jay Devore)](https://www.spps.org/cms/lib/MN01910242/Centricity/Domain/859/Statistics%20Textbook.pdf)

[3] [An Introduction to Probability and Simulation (Kevin Ross)](https://bookdown.org/kevin_davisross/probsim-book/)

[4] [The Elements of Statistical Learning - Data Mining, Inference and Prediction, Second Edition (Hastie et al)](https://hastie.su.domains/Papers/ESLII.pdf)

[5] [Interpretable Machine Learning - A Guide for Making Black Box Models Explainable, Second Edition (Christoph Molnar)](https://christophm.github.io/interpretable-ml-book/tree.html)
